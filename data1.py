# -*- coding: utf-8 -*-
"""data1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X-AH-wS_GkCnzoRoMudLmg0ptI79nRA4

Süeda Sena SÖNMEZ-180255023-İ.Ö
"""

from keras.models import Sequential
from numpy import loadtxt
from keras.layers import Dense,Dropout
from sklearn.preprocessing import LabelEncoder
from google.colab import drive
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sbn
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import mean_squared_error,r2_score
from sklearn import model_selection
from sklearn.neighbors import KNeighborsRegressor
from warnings import filterwarnings
filterwarnings("ignore")
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

drive.mount('/content/drive')

dataset=pd.read_excel(r'/content/drive/MyDrive/Derinogrenme/data-1.xlsx')
dataset.shape

dataset

le = LabelEncoder()
dataset['Class'] = le.fit_transform(dataset['Class'])
dataset

dataset["Class"].value_counts()

#Girdiler ve çıktılar belirlenir

y=dataset['Class']
x=dataset.drop(["Class"],axis=1)
#x=dataset.iloc[0:3810,1:]
#y=dataset.iloc[0:3810,:8]

#x=dataset[:0:8]
#y=dataset[:8]
#x.shape
x.shape
y.shape

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42,shuffle=True)

x_train.shape

x_test.shape

y_test.shape

y_train.shape

dataset.columns

x = dataset.iloc[:,:-1].values
y = dataset.iloc[:,:-1].values
mms=MinMaxScaler(feature_range=(0,3))
rescaled_x=mms.fit_transform(x)
np.set_printoptions(precision=4)

from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
x_train = mms.fit_transform(x_train) #Eğitim setine normalizasyon uygulamak
x_test= mms.transform(x_test) #Test setine normalizasyon uygulamak
x_test

model = Sequential()
model.add(Dense(128,input_shape=(None, 7), activation='relu'))

model.add(Dense(64, activation='relu'))

model.add(Dense(1, activation='sigmoid'))
model.summary()

model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])

history=model.fit(x_train,y_train,epochs=200,batch_size=10, validation_split=0.1)

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

scores = model.evaluate(x_train,y_train)
print("Training Accuracy: %.2f%%\n" % (scores[1]*100))
scores = model.evaluate(x_test,y_test)
print("Testing Accuracy: %.2f%%\n" % (scores[1]*100))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
y_pred_test = model.predict(x_test)
y_pred=[]
for i in y_pred_test:
  if(i>=0.3):
    y_pred.append(1)
  else:
    y_pred.append(0)
print(y_pred)
cm = confusion_matrix(y_test,y_pred)
ax = sns.heatmap(cm, annot=True, xticklabels=['Commeo','Osmancik'], yticklabels=['Commeo','Osmancik'],
                cbar=False,cmap='Blues')
ax.set_xlabel('Prediction')
ax.set_ylabel('Actual')
plt.show()

TP=cm[1,1]
TN=cm[0,0]
FP = cm[0,1]
FN = cm[1,0]
print(TP,TN,FP,FN)

sensitivity=TP / float(TP+FN)
print("SENSİTİVİTY= %.2f%%\n" %(sensitivity*100))
specifity=TN / float(TN+FP)
print("SPECİFİTY= %.2f%%\n"%(specifity*100))
precision=TP/float(TP+FP)
print("PRECİSİON=%.2f%%\n"%(precision*100))
f1_score=TP/float(TP+1/2*(FP+FN))
print("F1 SCORE=%.2f%%\n"%(f1_score*100))